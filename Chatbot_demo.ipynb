{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2018, 2, 17, 15, 0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dateparser import parse\n",
    "\n",
    "parse(\"today 3 PM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "today 29 34 DATE\n",
      "3 PM 38 42 TIME\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(sample2)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I -PRON- PRON PRP nsubj X True False\n",
      "will will VERB MD aux xxxx True True\n",
      "be be VERB VB aux xx True True\n",
      "playing play VERB VBG ROOT xxxx True False\n",
      "Basketball basketball PROPN NNP dobj Xxxxx True False\n",
      "today today NOUN NN npadvmod xxxx True False\n",
      "at at ADP IN prep xx True True\n",
      "3 3 NUM CD nummod d False False\n",
      "PM pm NOUN NN pobj XX True False\n",
      "! ! PUNCT . punct ! False False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "          token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample1 = \"Did anyone play basketball 1 week and one day ago?\"\n",
    "sample2 = \"I will be playing Basketball today at 3 PM!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from dateparser import parse\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def deduce_action(sentence):\n",
    "    l_sentences = []\n",
    "    i_pos = 0\n",
    "    e_pos = 0\n",
    "    \n",
    "    while e_pos < len(sentence):\n",
    "        if sentence[e_pos] in ('.', '!', '?'):\n",
    "            l_sentences.append(sentence[i_pos:e_pos+1].strip())\n",
    "            i_pos = e_pos + 1\n",
    "        e_pos += 1\n",
    "    if e_pos != i_pos:\n",
    "        l_sentences.append(sentence[i_pos: e_pos+1].strip())\n",
    "    \n",
    "    result = []\n",
    "    for x in l_sentences:\n",
    "        result.append(action_per_sentence(x))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def action_per_sentence(sentence):\n",
    "    \n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    result_dict = {}\n",
    "    compound_flag = False\n",
    "    q = []\n",
    "    for token in doc:\n",
    "        if token.dep_ == 'ROOT':\n",
    "            result_dict['action'] = ' '.join(q + [token.lemma_])\n",
    "        elif token.dep_ == 'dobj':\n",
    "            result_dict['what'] = ' '.join(q + [token.text])\n",
    "        elif token.dep_ == 'nsubj':\n",
    "            if 'who' not in result_dict:\n",
    "                result_dict['who'] = ' '.join(q + [token.text])\n",
    "        elif token.dep_ == 'punct':\n",
    "            if token.lemma_ == '?':\n",
    "                result_dict['question'] = True\n",
    "            else:\n",
    "                result_dict['question'] = False\n",
    "        elif token.dep_ == 'pobj':\n",
    "            if 'who' not in result_dict:\n",
    "                result_dict['who'] = ' '.join(q + [token.text])\n",
    "            else:\n",
    "                result_dict['who'] += \" \" + ' '.join(q + [token.text])\n",
    "        elif token.dep_ == 'xcomp':\n",
    "            result_dict['action'] = ' '.join(q + [token.text])\n",
    "        \n",
    "        if token.dep_ == 'compound' or token.dep_ == 'nummod' or \\\n",
    "            token.dep_ == 'npadvmod' or token.dep_ == 'poss' \\\n",
    "            or token.dep_ == 'attr' or token.dep_ == 'prep':\n",
    "            compound_flag = True\n",
    "            q.append(token.text)\n",
    "        else:\n",
    "            compound_flag = False\n",
    "            q = []\n",
    "            \n",
    "#         print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "#           token.shape_, token.is_alpha, token.is_stop)\n",
    "        \n",
    "    \n",
    "    time_measures = []\n",
    "    locations = []\n",
    "    people = []\n",
    "#     print(\"\\n\")\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'DATE' or ent.label_ == 'TIME':\n",
    "            time_measures.append(ent.text)\n",
    "        elif ent.label_ == 'GPE':\n",
    "            locations.append(ent.text)\n",
    "        elif ent.label_ == 'PERSON':\n",
    "            people.append(ent.text)\n",
    "        \n",
    "#         print(ent.text, ent.label_)\n",
    "    \n",
    "    date_parse_res = parse(' '.join(time_measures))\n",
    "#     print(time_measures)\n",
    "#     print(date_parse_res)\n",
    "    result_dict['when'] = 'Anytime'\n",
    "    if date_parse_res is not None:\n",
    "        result_dict['when'] = date_parse_res\n",
    "    result_dict['where'] = locations\n",
    "    result_dict['people'] = people\n",
    "    \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = deduce_action(\"When am I going to get a coop?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concern!\n"
     ]
    }
   ],
   "source": [
    "with open('concern_verb_list.txt', 'r') as f:\n",
    "    concern_verbs = f.read().split()\n",
    "\n",
    "res = deduce_action(\"We need to fix the pothole on Road 2.\")\n",
    "\n",
    "if res[0]['action'] in concern_verbs:\n",
    "    print(\"Concern!\")\n",
    "else:\n",
    "    print(\"Event!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
